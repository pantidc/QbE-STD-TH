{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_data = {}\n",
    "words = os.listdir(\"dataset_directory\")\n",
    "for word in words:\n",
    "    audio_files = os.listdir(f\"dataset_directory/{word}\")\n",
    "    audio_data[word] = [librosa.load(f\"dataset_directory/{word}/{file}\")[0] for file in audio_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_length = 16000  # 1 second clips at 16kHz\n",
    "\n",
    "X, y = [], []\n",
    "for word, audio_clips in audio_data.items():\n",
    "    for clip in audio_clips:\n",
    "        if len(clip) < fixed_length:\n",
    "            clip = np.pad(clip, (0, fixed_length - len(clip)))\n",
    "        else:\n",
    "            clip = clip[:fixed_length]\n",
    "        \n",
    "        # Normalize\n",
    "        clip = clip / np.linalg.norm(clip)\n",
    "        \n",
    "        X.append(clip)\n",
    "        y.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Truncate the data\n",
    "batch_size = 64\n",
    "data_size = len(X)\n",
    "truncated_size = (data_size // batch_size) * batch_size\n",
    "X = X[:truncated_size]\n",
    "y = y [:truncated_size]\n",
    "\n",
    "nums_step = data_size/batch_size\n",
    "print(nums_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to integers\n",
    "label_map = {label: i for i, label in enumerate(np.unique(y))}\n",
    "y = np.array([label_map[label] for label in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data to TensorFlow Dataset\n",
    "full_dataset = tf.data.Dataset.from_tensor_slices((X, y))\n",
    "\n",
    "# Shuffle the full dataset\n",
    "full_dataset = full_dataset.shuffle(buffer_size=len(X))\n",
    "\n",
    "# Calculate the size of train and test datasets\n",
    "total_size = len(X)\n",
    "train_size = int(0.8 * total_size)\n",
    "test_size = total_size - train_size\n",
    "\n",
    "# Perform the train-test split\n",
    "train_dataset = full_dataset.take(train_size)\n",
    "test_dataset = full_dataset.skip(train_size)\n",
    "\n",
    "# Optionally, you can also batch the datasets\n",
    "train_dataset = train_dataset.batch(32)\n",
    "test_dataset = test_dataset.batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = len(words)\n",
    "input_shape = (fixed_length, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Definition\n",
    "class WordDiscriminationModel(tf.keras.Model):\n",
    "    def __init__(self, num_words):\n",
    "        super(WordDiscriminationModel, self).__init__()\n",
    "        \n",
    "        self.reshape = tf.keras.layers.Reshape((fixed_length, 1), input_shape=input_shape)\n",
    "        self.conv1 = tf.keras.layers.Conv1D(8, 13, padding='valid', activation='relu')\n",
    "        self.maxpool1 = tf.keras.layers.MaxPooling1D(3)\n",
    "        self.conv2 = tf.keras.layers.Conv1D(16, 11, padding='valid', activation='relu')\n",
    "        self.maxpool2 = tf.keras.layers.MaxPooling1D(3)\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.dense1 = tf.keras.layers.Dense(64, activation=None)\n",
    "        self.dense2 = tf.keras.layers.Dense(num_words, activation='softmax')\n",
    "        \n",
    "    def call(self, x):\n",
    "   \n",
    "        x = self.reshape(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_embedding_model(base_model):\n",
    "    inputs = tf.keras.layers.Input(shape=(fixed_length,))\n",
    "    x = base_model.reshape(inputs)\n",
    "    x = base_model.conv1(x)\n",
    "    x = base_model.maxpool1(x)\n",
    "    x = base_model.conv2(x)\n",
    "    x = base_model.maxpool2(x)\n",
    "    x = base_model.flatten(x)\n",
    "    outputs = base_model.dense1(x)\n",
    "    return tf.keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dwd_loss(y_true, y_pred,labels, embeddings, N_word, M):\n",
    "    # Compute Centroids\n",
    "    #print(\"loss cal\")\n",
    "    centroids = []\n",
    "    for j in range(N_word):\n",
    "        emb_j = embeddings[j * M: (j + 1) * M]  # [M, emb_dim]\n",
    "        centroid_j = tf.reduce_sum(emb_j, axis=0, keepdims=True) / (M - 1)  # [1, emb_dim]\n",
    "        centroids.append(centroid_j)\n",
    "    centroids = tf.concat(centroids, axis=0)  # [N_word, emb_dim]\n",
    "\n",
    "    # Compute Cosine Similarity\n",
    "    normalized_embeddings = tf.nn.l2_normalize(embeddings, axis=-1)\n",
    "    normalized_centroids = tf.nn.l2_normalize(centroids, axis=-1)\n",
    "    similarity_matrix = tf.matmul(normalized_embeddings, normalized_centroids, transpose_b=True)  # [N_word * M, N_word]\n",
    "\n",
    "    # Softmax loss\n",
    "    true_similarity = tf.linalg.diag_part(tf.gather(similarity_matrix, labels, axis=1))  # [N_word * M]\n",
    "    L_sm = -true_similarity + tf.math.log(tf.reduce_sum(tf.exp(similarity_matrix), axis=1))  # [N_word * M]\n",
    "\n",
    "    # Contrastive Centroid Loss\n",
    "    S_ii = true_similarity  # [N_word * M]\n",
    "    S_ik = tf.reduce_max(similarity_matrix - tf.one_hot(labels, N_word) * 1e6, axis=1)  # [N_word * M]\n",
    "    L_cc = (1 - S_ii) + S_ik\n",
    "\n",
    "    # DWD loss\n",
    "    L_dwd = L_sm + L_cc\n",
    "    # Standard cross-entropy loss\n",
    "    xentropy_loss = tf.keras.losses.sparse_categorical_crossentropy(y_true, y_pred)\n",
    "    # Combined loss\n",
    "    final_loss = xentropy_loss + L_dwd\n",
    "    return final_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model = WordDiscriminationModel(num_words=num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Function and Optimizer\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "# Variables for early stopping\n",
    "best_val_loss = float('inf')  # Initialize to a large value\n",
    "no_improvement_epochs = 0  # Count epochs with no improvement in validation loss\n",
    "increasing_loss_epochs = 0  # Count epochs with an increasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_word = num_words  # Number of unique words\n",
    "M = 3  # Number of samples per word in each batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize metrics\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "val_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "# Custom Training Loop\n",
    "for epoch in range(500):  # Replace 50 with your desired number of epochs\n",
    "    # Training\n",
    "    #print(\"train\")\n",
    "    for train_x, train_y in train_dataset:\n",
    "        #print(\"step\")\n",
    "        with tf.GradientTape() as tape:\n",
    "            preds = model(train_x)\n",
    "            # Extract embeddings (output of dense1 layer)\n",
    "            embeddings = model.dense1(model.flatten(model.maxpool2(model.conv2(model.maxpool1(model.conv1(model.reshape(train_x)))))))\n",
    "           \n",
    "            #print(embeddings)\n",
    "            # Compute custom loss\n",
    "            # print(\"preds\")\n",
    "            # print(preds)\n",
    "            # print(\"train_y\")\n",
    "            # print(train_y)\n",
    "            # print(\"embeddings\")\n",
    "            # print(embeddings)\n",
    "            # print(\"centroid_dict\")\n",
    "            # print(centroid_dict)\n",
    "            loss = dwd_loss(train_y, preds,train_y, embeddings, N_spk, M)\n",
    "\n",
    "        # Gradient Descent\n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "        # Update accuracy metric\n",
    "        train_accuracy.update_state(train_y, preds)\n",
    "    \n",
    "    print(f\"Training Accuracy after epoch {epoch}: {train_accuracy.result().numpy()}\")\n",
    "    train_accuracy.reset_states()\n",
    "    #print(\"Validation\")\n",
    "    # Validation\n",
    "    val_loss = 0\n",
    "    val_steps = 0\n",
    "    \n",
    "    for test_x, test_y in test_dataset:\n",
    "        # Get predictions and embeddings\n",
    "        val_preds = model(test_x)\n",
    "\n",
    "        val_embeddings = model.dense1(model.flatten(model.maxpool2(model.conv2(model.maxpool1(model.conv1(model.reshape(test_x)))))))\n",
    "       \n",
    "        # Compute validation loss using the custom loss function\n",
    "\n",
    "        batch_val_loss = dwd_loss(test_y, val_preds,test_y, val_embeddings, N_spk, M)\n",
    "        val_loss += batch_val_loss\n",
    "        val_steps += 1\n",
    "        val_accuracy.update_state(test_y, val_preds)\n",
    "\n",
    "    val_loss /= val_steps  # Average loss over all validation batches\n",
    "    \n",
    "    ls_loss = loss.numpy().tolist()\n",
    "    ls_val_loss = val_loss.numpy().tolist()\n",
    "    training_loss =  sum(ls_loss) / len(ls_loss)\n",
    "    validation_loss = sum(ls_val_loss) / len(ls_val_loss)\n",
    "    print(f\"Epoch {epoch+1}: Training loss : {training_loss} , Validation Loss: {validation_loss}\")\n",
    "    print(f\"Validation Accuracy after epoch {epoch}: {val_accuracy.result().numpy()}\")\n",
    "    val_accuracy.reset_states()\n",
    "\n",
    "    # Early stopping logic\n",
    "    if validation_loss < best_val_loss:\n",
    "        best_val_loss = validation_loss\n",
    "        no_improvement_epochs = 0\n",
    "        increasing_loss_epochs = 0  # Reset counter\n",
    "    else:\n",
    "        no_improvement_epochs += 1\n",
    "        if validation_loss > best_val_loss:\n",
    "            increasing_loss_epochs += 1\n",
    "        else:\n",
    "            increasing_loss_epochs = 0  # Reset counter if loss is same but not increasing\n",
    "    \n",
    "    # Check early stopping conditions\n",
    "    if no_improvement_epochs >= 10 or increasing_loss_epochs >= 3:\n",
    "        print(f\"Early stopping triggered at epoch {epoch}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save(\"word_discrimination_model\",save_format='tf' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = build_embedding_model(model)\n",
    "embedding_model.save('word_embedding_model', save_format='tf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vector1, vector2):\n",
    "    # Compute the dot product of the two vectors\n",
    "    dot_product = np.dot(vector1, vector2)\n",
    "  \n",
    "    # Compute the L2 norm for each vector\n",
    "    norm1 = np.linalg.norm(vector1)\n",
    "    norm2 = np.linalg.norm(vector2)\n",
    "  \n",
    "    # Compute the cosine similarity\n",
    "    similarity = dot_product / (norm1 * norm2)\n",
    "  \n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "loaded_wordembedding_model = tf.keras.models.load_model(\"word_embedding_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_clip = librosa.load(\"audio_path1\")[0]\n",
    "\n",
    "if len(audio_clip) < fixed_length:\n",
    "    audio_clip = np.pad(audio_clip, (0, fixed_length - len(audio_clip)))\n",
    "else:\n",
    "    audio_clip = audio_clip[:fixed_length]\n",
    "\n",
    "# Normalize\n",
    "audio_clip = audio_clip / np.linalg.norm(audio_clip)\n",
    "\n",
    "audio_clip = audio_clip.reshape(1, -1)  # Reshape\n",
    "\n",
    "# Generate embedding\n",
    "\n",
    "embedding_of_word = loaded_wordembedding_model.predict(audio_clip)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_clip2 = librosa.load(\"audio_path2\")[0]\n",
    "\n",
    "if len(audio_clip2) < fixed_length:\n",
    "    audio_clip2 = np.pad(audio_clip2, (0, fixed_length - len(audio_clip2)))\n",
    "else:\n",
    "    audio_clip2 = audio_clip2[:fixed_length]\n",
    "\n",
    "\n",
    "# Assuming audio_clip is your input audio data, properly preprocessed\n",
    "audio_clip2 = audio_clip2 / np.linalg.norm(audio_clip2)  # Normalization\n",
    "audio_clip2 = audio_clip2.reshape(1, -1)  # Reshape\n",
    "\n",
    "# Generate embedding\n",
    "embedding_of_word2 = loaded_wordembedding_model.predict(audio_clip2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_of_word_f = embedding_of_word.flatten()\n",
    "embedding_of_wor2_f = embedding_of_word2.flatten()\n",
    "\n",
    "\n",
    "similarity_score = cosine_similarity(embedding_of_word_f, embedding_of_wor2_f)\n",
    "\n",
    "print(f\"Cosine Similarity Score: {similarity_score}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
